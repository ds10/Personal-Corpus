timestamp,text,"As academics, we have a tendency to think too much. There are pathologies of thought - the main one manifesting itself as a lack of humour, where all the earnestness and seriousness becomes a form of narcissism. The only defense is to pop our own bubble. That moment of revolt is a moment of freedom. It is where we step outside our abstractions (or someone else's abstraction that we got caught up in) and say ""this is a load of wank, isn't it?"" It is the 'wank' moment (or the 'bollocks' moment if your prefer) that is the real trigger for revolution: when leaders become figures of fun, the emporer is seen to have no clothes (clothes made out of piezoelectric fibre indeed!), and we all look at each other and laugh. Alethia is closely related to catharsis.There is a reason, I think, that the classical period in music stands out above all others. It is the period that subsumed humour as a structural principle. From Haydn's 'surprises' and jokes to Beethoven's Bagatelles and Mozart's farces, always in this music there is anticipation of the wise fool disrupting the proceedings, and in the process, setting everyone free. Of course, in literature, humour is there from the beginning, but assimilating it into music was a special moment because music is so much more elemental, and easily tempts us into worlds which are beautiful but otherworldly. The classical moment was the moment humans could situate themselves between the sublime beauty of other-worldliness and the decisive moments of comic intervention which would make everyone sit up.I've been making a lot of ""ambient"" electronic music recently. I find myself getting caught up in the melifluous fluctuations of sonority which seem to only be possible with electronics. Strangely, once started, these sonic environments are difficult to escape. ""What would Beethoven do?"" I ask myself. Well, he would want to break the flow; he would want to do something different. Because fundamentally, as human beings, that's what we are really about - doing something different. It is also the principle of intellectual endeavour.I remind myself of this as I look at the unfolding disaster of the UK Higher Education landscape and particular anxiously at what's happening in science. The dominance of big data cranking in almost every science is seductive in the same way as ambient music: everything becomes process. Who's going to blow the raspberry? Who's going to say the emporer hasn't any clothes? Who's going to say ""if we carry on doing this, we'll  forget what science is about""... (actually,  Bill Amos has said that recently: http://www.timeshighereducation.co.uk/comment/opinion/big-science-big-hype-big-mistake/2005124.article)Maybe it would help if we could refind a way to blow raspberries in ambient music! Most contemporary music is 'process music' - motoric rhythms, subtle changes of texture, clever transformations, inflections, timbres, etc are par for the course.  I've always felt Michael Tippett was ahead of his time because the spikiness of his music doesn't fit this pattern at all. He understood Beethoven better than anyone, and like Beethoven, he breaks movement with out-of-place outbursts. But that is the human moment - and Tippett's music speaks it more clearly than many other 20th century composers (maybe Shostakovich also knew about this). So Tippett may be my model.It's a model that's more broadly applicable though. When the education system has itself become subsumed into a process that nobody seems to be able to determine or control, and where everyone is in a kind of spaced-out confusion, we need to look for the raspberry blowers. Education needs its human moment quite urgently.","Pask's conversation theory is a rich and rather dense piece of work that few people outside the cybernetics community - within which he was a central figure - know. Thanks to Diana Laurillard however, most people know about the 'conversation model' - that model which situates learning as a coordination of communications between the teacher and the learner, where teachers judge their actions according to the feedback (or 'teach-back') given by learners. At a basic level, this appears defensible. However, the concept that does the most work in the conversation model, and in Pask's theory in general, is the concept of 'agreement'. I came across this video where Pask talks about 'agreement' in the context of his 'entailment meshes' (basically, the relationships between concepts). The problem with agreement is that a mechanistic approach that sees it as a coordination of speech acts, or other forms agency has many explanatory gaps when faced with real teaching and learning situations. Where is boredom? Where is novelty? Where is the feeling that either a learner or teacher might get that ""despite all the words being right, something's not connecting""? Where is empathy (there appears precious little of that in his presentation here!)? Where is enthusiasm? Where is passion for the subject? And perhaps most importantly, where is the explanation for our wanting an explanation in the first place?! Like a lot of cybernetic theories, there are no real people in Pask's model; only abstractions of people. That most human of attributes, agreement, is subsumed into an inhuman context.The problem with this is that an abstraction of person is basically the description of a process. Concepts fly into concepts, bound by some mysterious force which negotiates some kind of attraction or repulsion between them. (Pask was very fond of physical metaphors). But it all sounds a bit like Newtonian ""hard and massy"" particles. Concepts become related to fundamental mechanisms which by their operation alone can constitute the full richness of a person. But what of the person (Pask and friends) that want this to be true? To you and me they are awkward, funny, real (but dead, of course!) people - not constituted by fundamental mechanisms of 'P-individuals' and 'M-individuals'. Those technical terms are just the terms by which those real people (the real Gordon Pask) wants to know himself. But if he wants to know himself in such a constrained way, what does that tell the rest of us about him?Of course, I'm being a bit unfair. This isn't just about Pask. It's about EVERY lunatic social and psychological theorist who believes they can explain what a person is, whilst failing to see the person they are in wanting to do this! (I obviously include myself in this). Surely it can't be feasible to reduce a person an abstraction, or (worse) to a process?The physical analogies are interesting though, because one thing physics tells us is that whilst we may see mechanisms of hard and massy particles knocking into each other, there's a hell of a lot we can't see which nevertheless seems to play a big role in the process. It's not just 'dark matter', but the full gamut of unimaginable causal influences on things that happen.In physics and in learning, there is a common rule which I cannot sum up more simply than by saying: ""The thing that's missing is the thing that's missing.""Most importantly, that's not to say that the ""thing that's missing"" isn't causal. Dark matter is causal, but we only know the cause by its effects. In fact, as Hume pointed out centuries ago, we only know any cause by its effects (or at least, the regularity of its effects). The problem with ""the thing that's missing"" is that regularity is hard to come by - there can be no regularity with something that is missing.Pask was wrong because in his eagerness to overlook his own desire to explain conversation, and his eagerness to overlook the ""thing that's missing"", he failed to consider the ""thing that's missing"" as a fundamental part of conversation, and a fundamental part of agreement. I'm not writing this out of some clash of concepts in my head. I'm writing it because I sense something missing. There's another  way of saying this: I am not writing this as some logical consequence of what I already know or conversations I have had; I am writing it as the result of critical inspection. Being logical and being critical are different intellectual attitudes. The logical approach seeks to concretise ideas and form coherent structures out of them; the critical approach seeks to overcome the fears that sit behind the desire for the logical approach.Pask has a logical model of conversation and of agreement. In criticising it, I am advocating a critical approach to conversation instead. The coordinating forces in conversation are not coordinations around concepts, but coordinations around fears. Frightened teachers teach worst because fear typically leads them to take an authoritarian stance to students, so that they protect themselves from awkward questions. They could still be doing exactly what Pask says in his model, but the positioning between teacher and student would make the experience very different from an unafraid teacher.By saying we coordinate around fear, what I'm really saying is that the coordination is around 'what's missing'. The driver for learning - indeed, the driver for agreement - is critique, but what's missing emerges in the flow of experience which includes conversation. Much of experience just passes us by without any impact until a particular point when suddenly we realise what it was about. The way our expectations and realisations arise floating on a sea of redundant information is the great mystery of human experience. The irony is that since most of what passes is redundant, we take no notice of it. Yet it may be the most important thing: a melody without accompaniment is a pale shadow of the melody with its accompanimentThis is where Pask went wrong. He took the 'aboutness' of things - the topics - and tried to create a logical mechanism where aboutnesses interacted (in entailment meshes, agreements, and other paraphernalia). He lost sight of the things the aboutness was about. He lost sight of the redundancy upon which aboutness arises. He lost sight of what he'd lost sight of.","Text Mining tools and algorithms are becoming increasingly sophisticated. Most people are unaware of what can be revealed from the data that they post to Facebook, or the data they submit to Google through searching and using Gmail. We are now in a position where the global internet corporations know more about each of us that those closest to us; indeed, with their analytic tools, they may know more about us than we do ourselves.But text mining tools, whilst complex in their algorithms, are not rocket science. It wouldn't take much to provide these kinds of tools to ordinary learners and teachers. I'm finding the idea of empowering everyday users with sophisticated data mining tools increasingly attractive as a means of gaining greater personal autonomy in the face of global forces which are harvesting personal data for their own ends. So let's start with the idea of a ""personal corpus""A Personal Corpus is the sum total of the text you ever write. Emails, essays, tweets, etc. Everything goes in. Your data analytic tools can pick over it. You can do a particular kind of search with this sort of setup. Rather than say what you are looking for, instead you say what you think is the most important thing at a particular time: the ""topic"" of the moment. A ""topic"" is really a compression of  a lot of stories in a flow of information. What the analytic tools do is examine your ""topic"". It might look for occurrences of your topic in your corpus. But more importantly, it might look on the internet for other 'stories' relating to your topic. What emerges is a search corpus (drawn from the internet). The match between the search corpus and the personal corpus can then be calculated. It may be that the ""topic"" is something new; something you've never thought before. In this case, a process of recursive search can reveal sub-topics that might lead you from your chosen topic to the topics identified in your personal corpus. A path between your topic and the topics already in your corpus can be calculated.So, for example, you think the most important thing at the moment is a ""data mining"". I have a personal corpus (this blog!) which I can search for this. But a key word search is less revealing than a search where I compared all the expanded definitions and stories around 'data mining' with the narratives I already have in my personal corpus. Here I can look at the depth of matching, identify associated terms, and explore the links between those associated terms and my corpus. So I can identify, for example, that in 2010 I was talking about something like this, and maybe I would want to revisit some of this work. To me, that is valuable because I've been redirected to look not at some resource on the internet, but at something that was already within me.With a Personal Corpus, the relationship between the user and social software is reversed. Most social software tools are used for 'sharing' documents - social software serves as a repository. With the Personal Corpus, the internet and social software tools are used as a resource for data extraction; corpus data is not intended to be shared, but stored (maybe) locally in order to be analysed.With the Personal Corpus, individual users can determine the likely impact of particular social messages, whilst at the same time be able to get an insight  into the value that companies like Google might extract from that data. But more importantly, it provides greater personal autonomy through allowing users to explore the likely impact of different kinds of intervention.The Personal Corpus might be seen as an extension to E-portfolio tools (which never really took-off, did they?!) or to the Personal Learning Environment (which was hijacked by the axe-grinding blogeratti!) It might provide a way of really giving learners some useful tools which give them something back that might have some meaning for them...","Understanding the meaningfulness of communications in an organisation is the first step to understanding their ecology. An ecology requires a continuous stimulus for meaning generation. In order for this to occur, sufficiently different types of communication are necessary. Because of this, typical managerial interventions can upset the balance of ecological communications. The way to destroy any ecology (whether biological or communicative) is for one individual will to assert itself over all the others. It doesn't matter if the will is to drill a deep-sea oil well, or whether it is to sack half the staff; both the cause and the effect are the same: the cause is 'lack of listening' and the effect is catastrophe.We need to find a way of measuring communicative ecology. We now have sophisticated ways of measuring biological ecology, and I want to explore ways in which those techniques (and others) might be leveraged towards managing institutions better. The challenges are significant. Technology, particularly now we have 'big data' (for small minds!) can be leveraged by powerful people to justify any hare-brained scheme, giving little room for opposition in the face of 'evidence' that a decision is the right one. The problem lies in the poisonous combination of computer technology (as we know it) and cognitivism. It is cognitivism which encourages individuals (managers) to believe that they can alone compute the solution to the institutions problems by virtue of the fact that they alone have a better computer (their brain) and are privy to all the necessary information from their computers.To really deal with managerial pathologies, we have to deal with the problem of cognitivism, and in order to do that the fundamental metaphor that underpins it needs to be dismantled and re-assembled. This is the metaphor of the computer. Or rather, the Von Neumann/Turing computer which separates memory from processing. One of the really exciting things that emerged from the ASC conference was the interest shown in new conceptions of the computer: drawing on the earlier work of Beer and Pask, electro-chemical and biological computing appears to be exciting a lot of interest. Most important in this work is the lack of separation between the human being and the 'machine'. In this universe machines are sentient and the fundamental attachment relations not just between a single human and the machine, but the attachments between individuals becomes fundamental to the computation process. In this configuration, there can be no separation between man and machine, and no separation between processing and memory. All is structure. Because of this, no single individual is capable of computing anything alone. There is no 'alone'; we need each other to think.Which is where we get back to communicative ecology. The biological connection between structure, processing and memory, between man and (sentient) machine becomes a social structure. Understanding and analysing how that social structure is performing is likely to be the bread and butter of managing social ecologies.If we understood better how we really work, then there are sensible things that can be measured. In particular, we need to understand how it is we make a decision. Increasingly, I am convinced it is not the measure of information that matters in the making of decision, but the measure of redundancy. Redundancy has an autocatalytic effect on thought (another key issue emerging from the ASC conference, which was full of redundancy). Managing social ecologies may be about managing the generation of redundancies.Generating redundancy doesn't come easy in a society that is drilled for efficiency. But the efficiency drive can also be traced back to cognitivist myths. We are back to the challenge of challenging the received metaphor of intelligence, capability, thought, merit and productivity. Getting technical about reimagining computers may not seem like the game-changer that is required in the difficult circumstances we find ourselves. But there are currently computer scientists playing with things, saying to themselves ""this will change everything""... They've been right before.","The ASC's discussion conference at the University of Bolton has just finished (see http://asc-cybernetics.org/2013/). What a week it's been! Right now, I feel very proud of my University and its town. Bolton doesn't often see this kind of international influx of Americans plus a good number of other nationalities, and for a whole gang of them to descend onto the town's bars and restaurants and have a really great time was very heart warming. Their presence lit up the University: in the foyer in the mornings, groups of people with strange english accents were discussing interactive art, improvisation, sentient computing, big data, psychosis, education, learning, economics, music and sociology. This is the discussion that cybernetics is.It was the most intense conference I've ever been to. I'm only glad that I didn't have the jet-lag that most of the delegates had. It was also the most creative conference. The ASC's discussion conferences began in 2010 in Troy, NY at Rensselaer Polytechnic University. That conference was a remarkable experiment. In the presence of Ernst Von Glasersfeld, three days were devoted to discussing Mathematics, Art and Design, with artistic performances and paper presentations built around in the evenings. Many of the group at Rensselaer also came to Bolton: the feeling was that the dynamic creative energy from upstate New York had been transported to this little part of industrial northern England. I had to confess, I didn't think it would be possible before the conference.When the conference started, things started to fall in place. Risks that were taken in designing tasks for the participants (like ""make your own musical instrument"") turned into wonderfully rich expressions of creativity that set the tone for the discussions which followed. Then, having been given the (pretty difficult!) task of asking how acting, learning and understanding can be distinguished and are related, groups set about exploring the issues, often getting into deep water and finding their way out of it through heightened creativity and playful performances. The plenary sessions were where each group presented their findings. This was a driver for real innovation in the ways ideas were expressed.In the evening of the first day, there were artistic performances by some of the delegates who included Bill Seaman (http://billseaman.com/), Graham Clarke (http://www.grahamviolin.com/), a fascinatingly theatrical demonstration of Jennifer Kanary's psychosis simulator (http://www.labyrinthpsychotica.org/Labyrinth_Psychotica/Home.html) and Ranulph Glanville's electronic piece 'Blind'.Discussions continued the following day, with groups changing round and the focus shifting from Understanding to Acting. In the evening, papers were given. I saw presentations by Loet Leydesdorff on his work with Inga Ivanova on information redundancy and meaning (work which I have been fascinated by for a long time), Jerome Carson gave a revealing presentation about workplace stress, Faisal Kadri talked about artificial intelligence and emotion, and Narayana Mandaleeka from TATA spoke about value and quality improvement processes, and Tirumala Vinacotta (also from TATA) spoke of holistic thinking in business.There was a balance struck between the discussions and the academic content. Not everyone knew cybernetics to the same extent (there were tutorials on the day before the main conference). The overall impression of the conference was that it was a kind of retreat where cyberneticians could talk with each other at depth and seriousness about some very difficult topics. The difficulty of the topics meant that many discussions kept coming round to the same issues, but the repetition of this - rather than becoming boring - inspired greater creativity and playfulness. I find this the most interesting feature of the conference.Most conferences generate variety: lots of different papers, lots of topics - delegates have to attenuate the information by selecting what they are interested in. This conference generated redundancy: an extended (and sometimes repeated) conversation about a single topic - delegates had to be creative to deal with the redundancy. My thinking (drawing on Leydesdorff's thinking) is that redundancy is in some way autocatalytic: it creates the conditions where growth can occur. It may be too early to tell, but there was both personal growth and intellectual growth within the discipline occuring over the three days.A post-conference visit to Blackpool sealed what had been a very special time for those who were there. The University of Bolton will be fondly remembered by this group of remarkable thinkers as the place where many of their new ideas took root. ","In the Whitworth Gallery this lunchtime (catch it before it closes for a year of building work!) I was particularly struck by the wallpaper exhibition. The Whitworth is famous for its wallpaper  collection, but this time I found myself looking at it differently. Data redundancy is nowhere more explicit than wallpaper! Indeed, the connection between data redundancy and something 'not being there': after all, wallpaper is (by definition) background, not foreground. It's backgroundness appears dependent on the redundancy of its patterning. What is in the 'mood' that wallpaper is intended to create? Is it some kind of frame within which things can happen? Is there some kind of expectation that is established? The things which are meaningful exist in front of the wallpaper, but the wallpaper might contribute to their meaningfulness. If meaning is expectation, and expectation is prolonged by redundancy, then wallpaper serves a prolonging function. I might even suggest that it has a kind of 'catalytic' effect on thought as expectations are entertained. Why are some places inspirational? Is that to do with their patterning? Libraries have this effect on me. There is much patterning in the never-ending stacks of books. But an individual book might catch my attention and become meaningful: I become full of expectation. Is the prolonging of that expectation served by the patterning and regularity of the other books?Maybe the redundancy of wallpaper makes the making of redundancy more likely. It is the making of new redundancies that is fundamental to the kind of inner story-telling of intellectual life. Weak students struggle to create new redundancies, not to absorb new concepts. Computer interfaces are remarkably redundancy-free. Ironically, it is computer 'wallpaper' that is the most redundant part of them. I always preferred command lines to graphical windows. I now think it was for this reason: there is more redundancy in the command line: redundancy in the letters, redundancy in the typing, etc. I stare at this interface. Edit box. Text. There are buttons: submit, save, preview, close, compose, html. I look at 'tabs': Inbox, RStudio, Google, etc... Where is my mind? Where is my expectation? What is to maintain my expectation in the absence of any redundancy on the screen?I keep saying these sentences to myself. And that one. That's where the redundancy is. In my head. But I have to hold on to it. The computer seems to always want to take the redundancy away and commit it to a single entity...","I'm playing with YouTube's API at the moment as part of a paper I'm writing for the TRAILER project. TRAILER has created some rather ungainly tools for collecting information about informal learning. However, it has forced people to use these tools for at least one day (as part of 'user training'), and despite the fact that (frankly) a day was enough for most people in terms of using the tools, a significant amount of data was collected. Basically, users were asked to find resources on the internet that they felt reflected their own skills, and to tag them as indicators of their skills.Perhaps not surprisingly, most people tagged videos. From an extremely long list of competencies (""competency"" is a classic piece of Eurotwaddle which has resulted in very very long lists of pretty useless information! - Rabelais would love it!!) the user must select terms which describe how the resource reflects their skill. It's hardly surprising that there was little interest in continuing the torture. But nothing we do online these days is without some kind of consequences, and I'm interested what might be revealed about us through this simple activity.There are some interesting situations. If the competency that I choose for a resource is in some way unexpected or surprising, that is more interesting than if the competency I choose is consistent with the general expected reaction to the video. How can I know the general expected reaction? Well, we can do some data mining on the video resource to analyse comments, descriptions, related content, etc. So the YouTube API becomes useful. Basically, if the entropy of the competency term is low in relation to the entropy pattern of the analysis, there is little of interest. If it is high, then something unusual is going on. So that's the first interesting thing... We have a way of saying ""so-and-so is weird!""There are deeper comparisons to be made here. Because a surprising competency may itself be mined, and a comparison done concerning the common information content between the mined competency term and the mined video data. But this isn't so interesting unless the user goes on to select another resource.When they do that, a similar process can take place, but additionally, if the competency term is different, a comparison can be made between the common information content between a previous resource/competency match and subsequent ones. It is not inconceivable that patterns of information transfer might be discernible from this process.Typically, in a process of online engagement, we hone-in on things. Our first submissions are not as good as later submissions. In these cases of learning, we would expect to see information transfer from previous taggings and subsequent taggings: terms with low entropy in earlier submissions will take more prominance in later submissions. This would reflect an increasing ability to predict the fit between one's idea of a competency and the match with a resource. Having reached a peak, the information transfer will die-off once the pairing between resource and competency has been satisfactorily established. If no extra information can be added by selecting a competency, then there is no sense in doing it.But what's really going on here?When we do data mining, what usually happens is that key terms are identified. The rest is noise. In fact the rest is redundant. What I think is that 'key terms' are reflections of 'expectations' set up by a resource (a video, a piece of text). These ""expectations"" determine the theme: they help us to predict the course of the action. Ultimately, they help us determine what things mean.I also think that expectations are ""prolonged"" in some way. Our expectations do not change with every new piece of information, with every new moment in a video. But what keeps them active? I think the answer to this is ""redundancy"". The 'filler' is essential to the maintaining of the meaning of what is happening. We might remove the 'filler' to save time or computer memory, but we do so to invite other humans to reinvent the filler for themselves.A competency statement is a highly compressed piece of information usually completely free of redundancy. In articulating how they might meet a competency, a learner has to create redundancy around the competency statement. In normal life (outside the European Commission) we call this a ""story"". A video is an entity with high redundancy which is an example of someone else's ""story"". In claiming someone else's story, a learner is effectively trying to superimpose a 'compression' of that story as their competency claim. Their compression is open to interpretation. That means that others may see this and recreate their own redundancy (story) around it (possibly compressing the meta-narrative of the learner's use of these particular tools!).But the process of assigning a competency statement to a resource is also a way of trying to articulate the 'expectation' contained within that resource. But competencies don't relate to resources; they relate to people!! Seeking to associate a competency to a resource is a process of seeking to articulate one's own expectation of oneself. The demand is very ambitious: we ask people to identify what is meaningful in their lives. No wonder they struggle to do it. In fact, in many cases something else goes on: learners seek to articulate their expectations of the system they are using!This is where the ungainliness of the tools can be important. Computer interfaces tend to be redundancy-free. It is for the user to create their narratives through an interface. When users are introduced to a system, they are also introduced to the system designer's narrative. The designer's narrative frames the meaning of the tools and the expectation of the users. Within those expectations the designer will introduce the expectations of competencies, each of which might have its own narrative which the designer is unlikely to know (only the designers of the competencies will know that!). The user will generate their own redundancies (stories) about the expectations of the system and the use of the tools, but this narrative will be disconnected from the narrative they are challenged to write about how they meet particular competencies.In the system, a competency is claimed against a resource. The resource has 'expectations' and 'redundancies'; the competency is 'expectation', but it can be mined to show it also has redundancy. Between these patterns of expectations and redundancies, the learner must find their own redundancies around the expectations of the competency statement. But this is the hardest thing of all: in the process, they may well come to their own understanding of what the competency statement expectation is.The process of generating redundancy is a process of creativity. The difference between the highly competent learners and less competent learners is the difference not in their ability to claim competencies, but in their ability to generate redundancies.I'm hoping (perhaps vainly) that fiddling with big data APIs like YouTube, there might be a way of scaffolding the generation of redundancies through the kind of processes that TRAILER is trying to encourage... But might the disconnect between the ""narrative of the system"" and the ""narrative of the purpose of the system"" always get in the way? To what extent is this a bigger problem in our techno-educational institutions?"